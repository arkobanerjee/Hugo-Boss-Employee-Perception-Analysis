{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying textual attributes of the reviews into categories and defining sentiment, where neccessary\n",
    "-------------------\n",
    "\n",
    "> <i>Description: In this notebook, we classify text observations from reviews into one or more categories aligned with Hugo Boss's values and benefits. We also define the sentiment for columns where sentiment is not readily apparent.</i>\n",
    "\n",
    "We will use output file to further conduct our analysis.\n",
    "\n",
    "Input Files: \n",
    "1) reviews_merged.csv\n",
    "2) Kununu_rating_ids_mapped.xlsx\n",
    "\n",
    "Output:\n",
    "1) text_data_classes_sentiment.xlsx\n",
    "\n",
    "Model:  \n",
    "\n",
    "We used **GPT-4o-mini**, a state-of-the-art language model. This modelâ€™s large scale and advanced transformer-based architecture allow it to capture nuanced language and context, and accurately classify text  in line with Hugo Boss's values and benefits and assess sentiment.\n",
    "\n",
    "Categories: \n",
    "\n",
    "- **Diversity & Equity & Inclusion**: Keywords: Diversity, Inclusion, Equity, LGBTQIA+, Equal opportunities, Gender equality, homophobia, biphobia, transphobia, inequality, sexism, racism, inclusivity.\n",
    "  \n",
    "- **Authenticity**: Keywords: Authenticity, True self, Personal expression, Be yourself, Unique identities, independence.\n",
    "\n",
    "- **Collaboration & Teamwork & Social Culture**: Keywords: Collaboration, Teamwork, team spirit, Togetherness, Working together, Shared goals, social culture, team, Colleague, environment, atmosphere.\n",
    "\n",
    "- **Creativity and Innovation**: Keywords: Creativity, Innovation, New ideas, Originality, Forward-thinking, problem-solving.\n",
    "\n",
    "- **Professional Development and Continuous Learning**: Keywords: Development, Learning, Skills, Training, Courses, Self-improvement, Growth opportunities, promotion, Growth, Mentorship, Ownership, Entrepreneurial spirit, task.\n",
    "\n",
    "- **Youthful Spirit**: Keywords: Intern, working student, young, internship, hazing, youthful.\n",
    "\n",
    "- **Digital Transformation & Process Management**: Keywords: Digital, Transformation, Technology, Process improvement, Automation, Efficiency.\n",
    "\n",
    "- **Leadership & Communication**: Keywords: Leadership, Communication, management, Guidance, inspirational leadership, leader, manager, supervisor, feedback, Conflict, support.\n",
    "\n",
    "- **Fashion and Lifestyle Benefits**: Keywords: Clothing allowance, discount, ArtPass, Museum access, Hugo Boss stores, vip shops, Outlets.\n",
    "\n",
    "- **Health and Well-being**: Keywords: Mental health program, Life coaching, hotline, Gym, Fitness, insurance, Health events, Personal trainers, Stress management.\n",
    "\n",
    "- **Work-Life Balance & Flexibility**: Keywords: Mobile work, Remote work, 30 vacation days, Special leave, flexibility, Daycare, Kindergarten, Family services, Childcare support, Domestic help.\n",
    "\n",
    "- **Mobility & Accessibility**: Keywords: Job bike, Bike leasing, Mobility allowance, Public transport subsidies, E-charging stations, Shuttle service, Campus transportation.\n",
    "\n",
    "- **Financial Compensation & Benefits**: Keywords: Share investment, Company pension, salary, wage, Pension subsidies, Vacation bonuses, Christmas bonuses.\n",
    "\n",
    "- **Device Leasing and Corporate Benefits**: Keywords: Smartleasing, Apple devices, Samsung devices, Travel, Mobile phones.\n",
    "\n",
    "- **Social and Recreational Benefits**: Keywords: Celebration events, After-work events, Summer party, Christmas party, Food, Drinks, canteen, Live entertainment, On-campus restaurant, Coffee bar, Subsidized meals, Barista services.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reviews_merged.csv is a result of merging Glassdoor and Kununu translated files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews_merged.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "api_key = \"your_key\"\n",
    "# Set up your OpenAI API key\n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with categories and their keywords\n",
    "categories_keywords = {\n",
    "    \"Diversity & Equity & Inclusion\": \"Keywords: Diversity, Inclusion, Equity, LGBTQIA+, Equal opportunities, Gender equality, homophobia, biphobia, transphobia, inequality, sexism, racism, inclusivity\",\n",
    "    \"Authenticity\": \"Keywords: Authenticity, True self, Personal expression, Be yourself, Unique identities, independence.\",\n",
    "    \"Collaboration & Teamwork & Social Culture\": \"Keywords: Collaboration, Teamwork, team spirit, Togetherness, Working together, Shared goals, social culture, team, Colleague, environment, atmosphere\",\n",
    "    \"Creativity and Innovation\": \"Keywords: Creativity, Innovation, New ideas, Originality, Forward-thinking, problem-solving.\",\n",
    "    \"Professional Development and Continuous Learning\": \"Keywords: Development, Learning, Skills, Training, Courses, Self-improvement, Growth opportunities, promotion, Growth, Mentorship, Ownership, Entrepreneurial spirit, task.\",\n",
    "    \"Youthful Spirit\": \"Keywords: Intern, working student, young, internship, hazing, youthful.\",\n",
    "    \"Digital Transformation & Process Management\": \"Keywords: Digital, Transformation, Technology, Process improvement, Automation, Efficiency.\",\n",
    "    \"Leadership & Communication\": \"Keywords: Leadership, Communication, management, Guidance, inspirational leadership, leader, manager, supervisor, feedback, Conflict, support\",\n",
    "    \"Fashion and Lifestyle Benefits\": \"Keywords: Clothing allowance, discount, ArtPass, Museum access, Hugo Boss stores, vip shops, Outlets.\",\n",
    "    \"Health and Well-being\": \"Keywords: Mental health program, Life coaching, hotline, Gym, Fitness, insurance, Health events, Personal trainers, Stress management.\",\n",
    "    \"Work-Life Balance & Flexibility\": \"Keywords: Mobile work, Remote work, 30 vacation days, Special leave, flexibility, Daycare, Kindergarten, Family services, Childcare support, Domestic help.\",\n",
    "    \"Mobility & Accessibility\": \"Keywords: Job bike, Bike leasing, Mobility allowance, Public transport subsidies, E-charging stations, Shuttle service, Campus transportation.\",\n",
    "    \"Financial Compensation & Benefits\": \"Keywords: Share investment, Company pension, salary, wage, Pension subsidies, Vacation bonuses, Christmas bonuses.\",\n",
    "    \"Device Leasing and Corporate Benefits\": \"Keywords: Smartleasing, Apple devices, Samsung devices, Travel, Mobile phones.\",\n",
    "    \"Social and Recreational Benefits\": \"Keywords: Celebration events, After-work events, Summer party, Christmas party, Food, Drinks, canteen, Live entertainment, On-campus restaurant, Coffee bar, Subsidized meals, Barista services.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_with_keywords(text):\n",
    "    \"\"\"\n",
    "    Classifies the given text into one or more predefined categories based on associated keywords.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text to be classified.\n",
    "\n",
    "    Returns:\n",
    "    - str: A comma-separated string of categories to which the text belongs. \n",
    "           If the text does not match any category, returns \"NA\".\n",
    "\n",
    "    Error Handling:\n",
    "    If an error occurs during classification, the function prints the error message and returns \"NA\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Craft the system prompt, including category names and their associated keywords\n",
    "        prompt = f\"\"\"Classify the following text into one or more categories based on the keywords provided. If the text doesn't fit any category, return \"NA\". \n",
    "        Return multiple categories if applicable, separated by commas.\n",
    "\n",
    "Categories and Keywords:\n",
    "1. Diversity & Equity & Inclusion: {categories_keywords['Diversity & Equity & Inclusion']}\n",
    "2. Authenticity: {categories_keywords['Authenticity']}\n",
    "3. Collaboration & Teamwork & Social Culture: {categories_keywords['Collaboration & Teamwork & Social Culture']}\n",
    "4. Creativity and Innovation: {categories_keywords['Creativity and Innovation']}\n",
    "5. Professional Development and Continuous Learning: {categories_keywords['Professional Development and Continuous Learning']}\n",
    "6. Youthful Spirit: {categories_keywords['Youthful Spirit']}\n",
    "7. Digital Transformation & Process Management: {categories_keywords['Digital Transformation & Process Management']}\n",
    "8. Leadership & Communication: {categories_keywords['Leadership & Communication']}\n",
    "9. Fashion and Lifestyle Benefits: {categories_keywords['Fashion and Lifestyle Benefits']}\n",
    "10. Health and Well-being: {categories_keywords['Health and Well-being']}\n",
    "11. Work-Life Balance & Flexibility: {categories_keywords['Work-Life Balance & Flexibility']}\n",
    "12. Mobility & Accessibility: {categories_keywords['Mobility & Accessibility']}\n",
    "13. Financial Compensation & Benefits: {categories_keywords['Financial Compensation & Benefits']}\n",
    "14. Device Leasing and Corporate Benefits: {categories_keywords['Device Leasing and Corporate Benefits']}\n",
    "15. Social and Recreational Benefits: {categories_keywords['Social and Recreational Benefits']}\n",
    "\n",
    "If the text doesn't belong to any of these categories, return \"NA\".\n",
    "\n",
    "Text: {text}\n",
    "Categories (separated by commas):\"\"\"\n",
    "\n",
    "        # Use the provided OpenAI client to send the request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Extract and return the classification from the response\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "\n",
    "        # If response contains multiple categories, return them\n",
    "        return classification if classification else \"NA\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying text: {e}\")\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary column\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['summary_class'] = df['summary_translated'].progress_apply(classify_text_with_keywords)\n",
    "# To see if classification worked fine\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenated_ratings column\n",
    "tqdm.pandas()\n",
    "df['concatenated_ratings_class'] = df['concatenated_ratings'].progress_apply(classify_text_with_keywords)\n",
    "# To see if classification worked fine\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestion column\n",
    "tqdm.pandas()\n",
    "df['suggestion_class'] = df['suggestion'].progress_apply(classify_text_with_keywords)\n",
    "# To see if classification worked fine\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cons column\n",
    "tqdm.pandas()\n",
    "df['cons_class'] = df['cons'].progress_apply(classify_text_with_keywords)\n",
    "# To see if classification worked fine\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pros column\n",
    "tqdm.pandas()\n",
    "df['pros_class'] = df['pros'].progress_apply(classify_text_with_keywords)\n",
    "# To see if classification worked fine\n",
    "print(df.head())\n",
    "# You can use the line below to save intermediate result: \n",
    "# df.to_excel('classes_df.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observed that the **Financial Compensation & Benefits** category was not consistently assigned to texts mentioning salary or pay. To address this, we manually added the category using the `add_class_based_on_keyword` function, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function to add 'Financial Compensation & Benefits' class based on a keyword in a specified column\n",
    "def add_class_based_on_keyword(df, ratings_col, class_col, keywords, new_class):\n",
    "    \"\"\"\n",
    "    Adds a specified class label to rows in a DataFrame based on the presence of keywords within a given column.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pandas.DataFrame): The DataFrame containing the text to analyze.\n",
    "    - ratings_col (str): The column in the DataFrame where keywords will be searched for.\n",
    "    - class_col (str): The column where the new class will be added if a keyword is found.\n",
    "    - keywords (list): A list of keywords to look for within the specified ratings column.\n",
    "    - new_class (str): The class label to be added if any of the keywords are found.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The updated DataFrame with the new class labels added where applicable.\n",
    "    \"\"\"\n",
    "    def apply_logic(row):\n",
    "        # Convert NaN to empty string for both ratings_col and class_col\n",
    "        ratings_text = str(row[ratings_col]) if pd.notna(row[ratings_col]) else ''\n",
    "        class_text = str(row[class_col]) if pd.notna(row[class_col]) else ''\n",
    "        \n",
    "        # Check for any of the keywords in the ratings column\n",
    "        if any(keyword.lower() in ratings_text.lower() for keyword in keywords):\n",
    "            if new_class not in class_text:\n",
    "                return new_class + ', ' + class_text\n",
    "        return class_text\n",
    "\n",
    "    # Apply the logic to the specified columns\n",
    "    df[class_col] = df.apply(apply_logic, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['salary', 'pay']\n",
    "new_class = 'Financial Compensation & Benefits'\n",
    "\n",
    "# Applying the function for each pair of columns\n",
    "df = add_class_based_on_keyword(df, 'cons', 'cons_class', keywords, new_class)\n",
    "df = add_class_based_on_keyword(df, 'pros', 'pros_class', keywords, new_class)\n",
    "df = add_class_based_on_keyword(df, 'concatenated_ratings', 'concatenated_ratings_class', keywords, new_class)\n",
    "df = add_class_based_on_keyword(df, 'suggestion', 'suggestion_class', keywords, new_class)\n",
    "df = add_class_based_on_keyword(df, 'summary_translated', 'summary_class', keywords, new_class)\n",
    "\n",
    "# Use line below to save intermediate results\n",
    "# df.to_excel('salarypay.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1. Defining Sentiment using GPT-4o-mini\n",
    "\n",
    "Applied to columns, for which sentiment was not clear: Suammry, Suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    \"\"\"\n",
    "    Determines the sentiment of the given text as either 'positive', 'negative', or 'neutral'.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str): The input text for which sentiment is to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The sentiment of the text, which will be one of 'positive', 'negative', or 'neutral'. \n",
    "           Returns \"NA\" if the sentiment analysis fails.\n",
    "\n",
    "    Error Handling:\n",
    "    If an error occurs during the sentiment analysis process, the function prints the error message and returns \"NA\".\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Craft the system prompt, including category names and their associated keywords\n",
    "        prompt = f\"\"\"Analyze the sentiment of the following text and return the sentiment as 'positive', 'negative', or 'neutral'. \n",
    "\n",
    "Text: \"{text}\"\n",
    "\n",
    "Sentiment (positive, negative, neutral):\"\"\"\n",
    "\n",
    "        # Use the provided OpenAI client to send the request\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",  \n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Extract and return the classification from the response\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "\n",
    "        # If response contains multiple categories, return them\n",
    "        return classification if classification else \"NA\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying text: {e}\")\n",
    "        return \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying get_sentiment to summary column\n",
    "tqdm.pandas()\n",
    "df['summary_sentiment'] = df['summary_translated'].progress_apply(get_sentiment)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying get_sentiment to suggestion column\n",
    "tqdm.pandas()\n",
    "df['suggestion_sentiment'] = df['suggestion'].progress_apply(get_sentiment)\n",
    "print(df.head())\n",
    "# Use below line to save intermediate result: \n",
    "# df.to_excel('sentiment_summary_suggestion.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We noticed that NaN values were not handled properly, as well as the sentiment text value itself nedded some processing. We did it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentiment(sentiment):\n",
    "    \"\"\"\n",
    "    Cleans and standardizes the sentiment value by extracting only the relevant sentiment word \n",
    "    ('positive', 'negative', or 'neutral') from the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - sentiment (str): The sentiment string that may contain additional text or formatting.\n",
    "\n",
    "    Returns:\n",
    "    - str: The cleaned sentiment word in lowercase ('positive', 'negative', or 'neutral'). \n",
    "           If no valid sentiment word is found, returns the original sentiment input.\n",
    "\n",
    "    \"\"\"\n",
    "    if pd.isna(sentiment):\n",
    "        return sentiment\n",
    "    # Use regex to extract only the sentiment word (positive, negative, neutral)\n",
    "    cleaned_sentiment = re.search(r'(positive|negative|neutral)', sentiment, re.IGNORECASE)\n",
    "    return cleaned_sentiment.group(0).lower() if cleaned_sentiment else sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting NaN values to the sentiment column rows, for which original column has no text\n",
    "df.loc[df['summary_translated'].isna(), 'summary_sentiment'] = np.nan\n",
    "# Apply the cleaning function to the 'summary_sentiment' column\n",
    "df['summary_sentiment'] = df['summary_sentiment'].apply(clean_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting NaN values to the sentiment column rows, for which original column has no text\n",
    "df.loc[df['suggestion'].isna(), 'suggestion_sentiment'] = np.nan\n",
    "# Apply the cleaning function to the 'suggestion_sentiment' column\n",
    "df['suggestion_sentiment'] = df['suggestion_sentiment'].apply(clean_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2. Defining Sentiment using scores for each id\n",
    "\n",
    "Applied to columns, for which sentiment was not clear and text was too complicated and included several categories: Concatinated ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kununu_rating_ids_mapped.xlsx was created by mapping id names to categories\n",
    "df_mapping = pd.read_excel('Kununu_rating_ids_mapped.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Class Scores for Ratings\n",
    "\n",
    "This process iterates over each row in the DataFrame to calculate average scores for classified categories based on associated IDs.\n",
    "\n",
    "Steps:\n",
    "1. **Initialize a Storage List**: An empty list, `class_avg_list`, is created to store the new column values.\n",
    "\n",
    "2. **Iterate Through Rows**: Each row in the DataFrame is examined, starting with the column 'concatenated_ratings_class' to fetch class names.\n",
    "   - If the class information is NaN, NaN is appended to the results list, and processing moves to the next row.\n",
    "   \n",
    "3. **Split and Extract Classes**: Class names are split into individual categories, and a list of these classes is prepared for score calculation.\n",
    "\n",
    "4. **Parse Ratings Data**: The 'ratings_translated' column, containing JSON-like strings, is safely converted into a list of dictionaries.\n",
    "   - If parsing fails, an error message is logged, NaN is appended to `class_avg_list`, and the row is skipped.\n",
    "   \n",
    "5. **Match and Calculate Scores**:\n",
    "   - For each class, corresponding IDs are looked up in `df_mapping`.\n",
    "   - Scores associated with these IDs in 'ratings_translated' are extracted, and if multiple scores are found, their average is calculated.\n",
    "   - The results are formatted as \"ClassName Score\" or \"ClassName AvgScore\".\n",
    "\n",
    "6. **Store and Return Results**: The final class-score pairs are concatenated and appended to `class_avg_list`, which stores results in a structured \"ClassName Score\" format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the new column values\n",
    "class_avg_list = []\n",
    "\n",
    "# Iterate through each row in df['concatenated_ratings_class']\n",
    "for index, row in df.iterrows():\n",
    "    concatenated_classes = row['concatenated_ratings_class']\n",
    "    \n",
    "    # If the concatenated classes are NaN, append NaN and move to the next row\n",
    "    if pd.isna(concatenated_classes):\n",
    "        class_avg_list.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Split the concatenated classes into a list of individual class names\n",
    "    classes = [cls.strip() for cls in concatenated_classes.split(',')]\n",
    "    \n",
    "    class_score_pairs = []  # This will store each class and its score\n",
    "\n",
    "    # Safely convert the 'ratings_translated' string into a list of dictionaries\n",
    "    try:\n",
    "        score_entries = ast.literal_eval(row['ratings_translated'])  # Converting the string safely\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        # Log or handle parsing errors\n",
    "        print(f\"Error parsing ratings_translated in row {index}: {e}\")\n",
    "        class_avg_list.append(np.nan)\n",
    "        continue  # Skip if conversion fails\n",
    "    \n",
    "    # Loop through the classes for this particular observation\n",
    "    for cls in classes:\n",
    "        # Look up corresponding ID(s) in df_mapping\n",
    "        id_names = df_mapping[df_mapping['category'] == cls]['id'].tolist()\n",
    "        \n",
    "        # Handle cases where we find ID mappings\n",
    "        if id_names:\n",
    "            scores = []  # Collect all matching scores for the current class\n",
    "            \n",
    "            # Go through each id_name for the current class\n",
    "            for id_name in id_names:\n",
    "                # Find the score for the current id_name in the ratings_translated\n",
    "                matching_scores = [entry['score'] for entry in score_entries if entry['id'] == id_name]\n",
    "                \n",
    "                # If we find a score, append it to the scores list\n",
    "                if matching_scores:\n",
    "                    scores.extend(matching_scores)\n",
    "            \n",
    "            # If scores were found for the class, calculate the average or use the single score\n",
    "            if scores:\n",
    "                if len(scores) == 1:\n",
    "                    class_score_pairs.append(f\"{cls} {scores[0]}\")\n",
    "                else:\n",
    "                    avg_score = np.mean(scores)\n",
    "                    class_score_pairs.append(f\"{cls} {avg_score:.2f}\")\n",
    "    \n",
    "    # After processing all classes in this row, store the result in the format \"ClassName Score, ClassName Score\"\n",
    "    class_avg_list.append(', '.join(class_score_pairs))\n",
    "\n",
    "# After running this, let's check the first few results of the processed list\n",
    "class_avg_list[:10]\n",
    "\n",
    "# Adding the new column to df\n",
    "df['kununu_ratings_class_avg'] = class_avg_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average ratings can be further used as a sentiment. Fo example, if the score for a category is below 3, it means that the sentiment is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If applicable delete uneccessary columns\n",
    "# df = df.drop(columns=['...'])\n",
    "# Saving new df file as excel file\n",
    "df.to_excel('text_data_classes_sentiment.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of the notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
